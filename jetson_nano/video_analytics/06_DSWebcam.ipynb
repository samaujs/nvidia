{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0  Live Stream (Optional)\n",
    "### USB WEBCAM CONNECTED TO JETSON NANO REQUIRED\n",
    "\n",
    "In the examples presented so far, the input stream has been a file, played as a stream.  In this notebook, you'll use a live stream via a webcam. Attach a USB webcam to your Jetson Nano using an available USB port.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/06_example.png\" alt=\"webcam input\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 **[Build a Pipeline with Webcam Input](#06_overview)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 6.1.1 [Practice Application `deepstream-test1-webcam_in`](#06_base)<br>\n",
    "&nbsp; &nbsp; &nbsp; 6.1.2 [Exercise: Build and Run the Base Application](#06_ex_base)<br>\n",
    "6.2 **[Change the Network to YOLO](#06_yolo)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 6.2.1 [Exercise: Run YOLO with a Webcam](#06_ex_yolo)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_overview'></a>\n",
    "# 6.1 Build a Pipeline with Webcam Input\n",
    "The `deepstream-test1-webcam_in` application is a modification of the `deepstream-test1-rstp_out` application you explored in the first notebook. Compare the pipeline elements defined in the C code in [filesrc deepstream_test_app.c](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-rtsp_out/deepstream_test1_app.c) with the elements in [the webcam deepstream_test1_app.c](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in/deepstream_test1_app.c):\n",
    "\n",
    "**filesrc version**\n",
    "```c\n",
    "...\n",
    "\n",
    "  GstElement *pipeline = NULL, *source = NULL, *h264parser = NULL,\n",
    "      *decoder = NULL, *streammux = NULL, *sink = NULL, *pgie = NULL, *nvvidconv = NULL,\n",
    "      *nvosd = NULL, *encoder = NULL, *rtppay = NULL, *transform = NULL, *cap_filter = NULL;\n",
    "\n",
    "...\n",
    "   /* Source element for reading from the file */\n",
    "  source = gst_element_factory_make (\"filesrc\", \"file-source\");\n",
    "\n",
    "  /* Since the data format in the input file is elementary h264 stream,\n",
    "   * we need a h264parser */\n",
    "  h264parser = gst_element_factory_make (\"h264parse\", \"h264-parser\");\n",
    "\n",
    "  /* Use nvdec_h264 for hardware accelerated decode on GPU */\n",
    "  decoder = gst_element_factory_make (\"nvv4l2decoder\", \"nvv4l2-decoder\");\n",
    "\n",
    "  /* Create nvstreammux instance to form batches from one or more sources. */\n",
    "  streammux = gst_element_factory_make (\"nvstreammux\", \"stream-muxer\");\n",
    "\n",
    "...\n",
    "```\n",
    "**webcam version**\n",
    "```c\n",
    "...\n",
    "    \n",
    "  GstElement *pipeline = NULL, *source = NULL, *nvvidconv_src = NULL, *vidconv_src=NULL, \n",
    "      *filter_src=NULL, *streammux = NULL, *sink = NULL, *pgie = NULL, *nvvidconv = NULL,\n",
    "      *nvosd = NULL, *encoder = NULL, *rtppay = NULL, *transform = NULL, *cap_filter = NULL;\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "  source = gst_element_factory_make (\"v4l2src\", \"camera-source\");\n",
    "  g_object_set (G_OBJECT (source), \"device\", \"/dev/video0\", NULL);\n",
    "  vidconv_src = gst_element_factory_make (\"videoconvert\", \"vidconv_src\");\n",
    "  nvvidconv_src = gst_element_factory_make (\"nvvideoconvert\", \"nvvidconv_src\");\n",
    "  filter_src = gst_element_factory_make (\"capsfilter\", \"filter_src\");\n",
    "  g_object_set (G_OBJECT (nvvidconv_src), \"nvbuf-memory-type\", 0, NULL);\n",
    "  caps_filter_src =\n",
    "        gst_caps_from_string (\"video/x-raw(memory:NVMM), format=NV12, width=1280, height=720, framerate=30/1\");\n",
    "  g_object_set (G_OBJECT (filter_src), \"caps\", caps_filter_src, NULL);\n",
    "  gst_caps_unref (caps_filter_src);\n",
    "\n",
    "  /* Create nvstreammux instance to form batches from one or more sources. */\n",
    "  streammux = gst_element_factory_make (\"nvstreammux\", \"stream-muxer\");\n",
    "```    \n",
    "\n",
    "The remaining elements of the pipeline are the same.\n",
    "\n",
    "In summary, the pipeline for this app consists of the following plugins (ordered):\n",
    "\n",
    "- `GstV4l2Src` - can be used to capture video from v4l2 devices, like webcams and tv cards\n",
    "- `GstVideoConvert` - Convert video frames between a great variety of video formats\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (I420 to RGBA)\n",
    "- `GstCapsFilter` - enforces limitations on data (no data modification)\n",
    "- `GstH264Parse` - parses the incoming H264 stream\n",
    "- `Gst-nvv4l2decoder` - hardware accelerated decoder; decodes video streams using NVDEC\n",
    "- `Gst-nvstreammux` - batch video streams before sending for AI inference\n",
    "- `Gst-nvinfer` - runs inference using TensorRT\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (I420 to RGBA)\n",
    "- `Gst-nvdsosd` - draw bounding boxes, text and region of interest (ROI) polygons\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (RGBA to I420)\n",
    "- `GstCapsFilter` - enforces limitations on data (no data modification)\n",
    "- `Gst-nvv4l2h264enc` - encodes RAW data in I420 format to H264\n",
    "- `GstRtpH264Pay` - converts H264 encoded Payload to RTP packets (RFC 3984)\n",
    "- `GstUDPSink` - sends UDP packets to the network. When paired with RTP payloader (`Gst-rtph264pay`) it can implement RTP streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_base'></a>\n",
    "# 6.1.1 Practice Application `deepstream-test1-webcam_in`\n",
    "This app uses the Resnet10 primary detector provided with the DeepStream SDK.  You'll need to move the webcam over objects that the network can detect, i.e. Vehicle, Person, Bicycle, or Roadsign.  One way to accomplish this is to use a computer screen with these objects visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_ex_base'></a>\n",
    "# 6.1.2 Exercise: Build and Run the Base Application\n",
    "Plug in your webcam and execute the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in\n",
      "rm -rf deepstream_test1_app.o deepstream-test1-app\n",
      "cc -c -o deepstream_test1_app.o -DPLATFORM_TEGRA -I../../../includes `pkg-config --cflags gstreamer-1.0` deepstream_test1_app.c\n",
      "cc -o deepstream-test1-app deepstream_test1_app.o `pkg-config --libs gstreamer-1.0` -L/opt/nvidia/deepstream/deepstream-4.0/lib/ -lnvdsgst_meta -lnvds_meta -lgstrtspserver-1.0 -Wl,-rpath,/opt/nvidia/deepstream/deepstream-4.0/lib/\n"
     ]
    }
   ],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in/\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the DeepStream app with a CSI camera (modified on 1 Oct 2020)\n",
    "* Change the \"config-file-path\" from \"dstest1_pgie_config.txt\" to \"dstest1_pgie_config_yolov3.txt\" and comment \"gst_pad_add_probe\"\n",
    "* There will be a delay while the `.engine` file is built.\n",
    "\n",
    "Open the VLC media player on your laptop:\n",
    "- Click \"Media\" and open the  \"Open Network Stream\" dialog.\n",
    "- Set the URL to `rtsp://192.168.55.1:8554/ds-test`.\n",
    "- Start execution of the cell below.\n",
    "- Click \"Play\" on your VLC media player right after you start executing the cell.  \n",
    "\n",
    "The stream will start shortly from the Jetson Nano and display in the media player.  You may experience some lag, or may need to press the play button again on the player.  \n",
    "\n",
    "To stop the stream, click `Kernel -> Interrupt Kernel` from the JupyterLab menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in\n",
      "\n",
      " *** DeepStream: Launched RTSP Streaming at rtsp://localhost:8554/ds-test ***\n",
      "\n",
      "Now playing: (null)\n",
      "Opening in BLOCKING MODE \n",
      "Creating LL OSD context new\n",
      "0:00:04.240817984 \u001b[331m22896\u001b[00m   0x5595998840 \u001b[33;01mWARN   \u001b[00m \u001b[00m             nvinfer gstnvinfer.cpp:515:gst_nvinfer_logger:<primary-nvinference-engine>\u001b[00m NvDsInferContext[UID 1]:useEngineFile(): Failed to read from model engine file\n",
      "0:00:04.240911632 \u001b[331m22896\u001b[00m   0x5595998840 \u001b[36mINFO   \u001b[00m \u001b[00m             nvinfer gstnvinfer.cpp:519:gst_nvinfer_logger:<primary-nvinference-engine>\u001b[00m NvDsInferContext[UID 1]:initialize(): Trying to create engine from model files\n",
      "Loading pre-trained weights...\n",
      "Loading complete!\n",
      "Total Number of weights read : 8858734\n",
      "      layer               inp_size            out_size       weightPtr\n",
      "(1)   conv-bn-leaky     3 x 416 x 416      16 x 416 x 416    496   \n",
      "(2)   maxpool          16 x 416 x 416      16 x 208 x 208    496   \n",
      "(3)   conv-bn-leaky    16 x 208 x 208      32 x 208 x 208    5232  \n",
      "(4)   maxpool          32 x 208 x 208      32 x 104 x 104    5232  \n",
      "(5)   conv-bn-leaky    32 x 104 x 104      64 x 104 x 104    23920 \n",
      "(6)   maxpool          64 x 104 x 104      64 x  52 x  52    23920 \n",
      "(7)   conv-bn-leaky    64 x  52 x  52     128 x  52 x  52    98160 \n",
      "(8)   maxpool         128 x  52 x  52     128 x  26 x  26    98160 \n",
      "(9)   conv-bn-leaky   128 x  26 x  26     256 x  26 x  26    394096\n",
      "(10)  maxpool         256 x  26 x  26     256 x  13 x  13    394096\n",
      "(11)  conv-bn-leaky   256 x  13 x  13     512 x  13 x  13    1575792\n",
      "(12)  maxpool         512 x  13 x  13     512 x  13 x  13    1575792\n",
      "(13)  conv-bn-leaky   512 x  13 x  13    1024 x  13 x  13    6298480\n",
      "(14)  conv-bn-leaky  1024 x  13 x  13     256 x  13 x  13    6561648\n",
      "(15)  conv-bn-leaky   256 x  13 x  13     512 x  13 x  13    7743344\n",
      "(16)  conv-linear     512 x  13 x  13     255 x  13 x  13    7874159\n",
      "(17)  yolo            255 x  13 x  13     255 x  13 x  13    7874159\n",
      "(18)  route                  -            256 x  13 x  13    7874159\n",
      "(19)  conv-bn-leaky   256 x  13 x  13     128 x  13 x  13    7907439\n",
      "(20)  upsample        128 x  13 x  13     128 x  26 x  26        - \n",
      "(21)  route                  -            384 x  26 x  26    7907439\n",
      "(22)  conv-bn-leaky   384 x  26 x  26     256 x  26 x  26    8793199\n",
      "(23)  conv-linear     256 x  26 x  26     255 x  26 x  26    8858734\n",
      "(24)  yolo            255 x  26 x  26     255 x  26 x  26    8858734\n",
      "Output blob names :\n",
      "yolo_17\n",
      "yolo_24\n",
      "Total number of layers: 50\n",
      "Total number of layers on DLA: 0\n",
      "Building the TensorRT Engine...\n",
      "Building complete!\n",
      "0:01:17.417382658 \u001b[331m22896\u001b[00m   0x5595998840 \u001b[36mINFO   \u001b[00m \u001b[00m             nvinfer gstnvinfer.cpp:519:gst_nvinfer_logger:<primary-nvinference-engine>\u001b[00m NvDsInferContext[UID 1]:generateTRTModel(): Storing the serialized cuda engine to file at /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in/model_b1_fp32.engine\n",
      "Deserialize yoloLayerV3 plugin: yolo_17\n",
      "Deserialize yoloLayerV3 plugin: yolo_24\n",
      "Running...\n",
      "Creating LL OSD context new\n",
      "NvMMLiteOpen : Block : BlockType = 4 \n",
      "===== NVMEDIA: NVENC =====\n",
      "NvMMLiteBlockCreate : Block : BlockType = 4 \n",
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3264 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3264 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 120.000005 fps Duration = 8333333 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 4 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 120.000005 \n",
      "GST_ARGUS: PowerService: requested_clock_Hz=627200000\n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n",
      "H264: Profile = 66, Level = 0 \n",
      "\n",
      "(deepstream-test1-app:22896): GLib-GObject-\u001b[1;33mWARNING\u001b[0m **: \u001b[34m21:09:21.703\u001b[0m: g_object_get_is_valid_property: object class 'GstUDPSrc' has no property named 'pt'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in/\n",
    "!./deepstream-test1-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_yolo'></a>\n",
    "# 6.2 Change the Network to YOLO\n",
    "If you set up the YOLO network in the optional [Using Different Networks]() notebook, you will be able to identify many more objects with your webcam (up to 80!).  The `deepstream-test1-webcam_in-yolo` is very similar to the `deepstream-test1-webcam_in` app, but configured for YOLO.  To see the actual difference in lines, execute the following `diff` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/\n",
    "!diff deepstream-test1-webcam_in/deepstream_test1_app.c deepstream-test1-webcam_in-yolo/deepstream_test1_app.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_ex_yolo'></a>\n",
    "# 6.2.1 Run YOLO with a Webcam\n",
    "There will be a delay while the `.engine` file is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in-yolo/\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in-yolo/\n",
    "!./deepstream-test1-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_ex_yolo'></a>\n",
    "# 6.2.2 Run YOLO with a CSI camera\n",
    "\n",
    "### Change the \"config-file-path\" from \"dstest1_pgie_config.txt\" to \"dstest1_pgie_config_yolov3.txt\" and comment \"gst_pad_add_probe\"\n",
    "\n",
    "There will be a delay while the `.engine` file is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-csicam_in-yolo/\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-csicam_in-yolo/\n",
    "!./deepstream-test1-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've completed all the notebooks.  Be sure to work through the assessment questions in the online portion of the DLI course to get your certificate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
